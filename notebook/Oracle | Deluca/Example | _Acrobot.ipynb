{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3021d8d-aa88-4c40-897c-8892da6c4d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dt': 0.2,\n",
       " 'LINK_LENGTH_1': 1.0,\n",
       " 'LINK_LENGTH_2': 1.0,\n",
       " 'LINK_MASS_1': 1.0,\n",
       " 'LINK_MASS_2': 1.0,\n",
       " 'LINK_COM_POS_1': 0.5,\n",
       " 'LINK_COM_POS_2': 0.5,\n",
       " 'LINK_MOI': 1.0,\n",
       " 'MAX_VEL_1': 12.566370614359172,\n",
       " 'MAX_VEL_2': 28.274333882308138,\n",
       " 'AVAIL_TORQUE': DeviceArray([-1.,  0.,  1.], dtype=float32),\n",
       " 'torque_noise_max': 0.0,\n",
       " 'book_or_nips': 'book',\n",
       " 'action_arrow': None,\n",
       " 'domain_fig': None,\n",
       " 'actions_num': 3,\n",
       " 'action_size': 3,\n",
       " 'action_type': 'discrete',\n",
       " 'max_episode_steps': 500}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jax\n",
    "import tax\n",
    "import tqdm\n",
    "import haiku as hk\n",
    "import numpy as np\n",
    "import collections \n",
    "import jax.numpy as jnp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import mbrl\n",
    "\n",
    "from jax import jit\n",
    "from functools import partial\n",
    "from mbrl.envs.oracle._acrobot import env_params, dynamics, render\n",
    "from mbrl.envs.oracle._acrobot import reset_fn, step_fn\n",
    "from mbrl.algs.rs import forecast\n",
    "from mbrl.algs.rs import plan\n",
    "from mbrl.algs.rs import score\n",
    "\n",
    "rng = jax.random.PRNGKey(42)\n",
    "Environment = collections.namedtuple('Environment', ['step', 'reset'])\n",
    "\n",
    "env_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67fc296d-d90e-40b4-9d7c-68054f897b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_fn = jit(partial(step_fn, env_params=env_params))\n",
    "reset_fn = jit(partial(reset_fn, env_params=env_params))\n",
    "dynamics = jit(partial(dynamics, env_params=env_params))\n",
    "env = Environment(step=step_fn, reset=reset_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80e0c0a7-0b9d-41b6-814d-fce1d2d604df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DeviceArray([-0.00265431,  0.04787853, -0.08390957, -0.1455917 ], dtype=float32),\n",
       " DeviceArray([ 0.9999965 , -0.00265431,  0.99885404,  0.04786024,\n",
       "              -0.08390957, -0.1455917 ], dtype=float32),\n",
       " DeviceArray(-1., dtype=float32),\n",
       " DeviceArray(0., dtype=float32),\n",
       " {})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_0, observation_0 = reset_fn(rng)\n",
    "u = 1      # 0, 1, 2\n",
    "dynamics(state_0, u)\n",
    "step_fn(state_0, u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7e3b8e4e-b549-4ec4-8156-4def323ae267",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def world(carry, t):\n",
    "    keys, (state, observation), trajectory = carry\n",
    "    action = trajectory[t]\n",
    "    rng = keys[t]\n",
    "    state_next, observation_next, reward, done, info = env.step(state, action)\n",
    "    reward = reward.astype(jnp.float32)\n",
    "    carry = keys, (state_next, observation_next), trajectory\n",
    "    return carry, {\n",
    "        \"state\": state,\n",
    "        \"state_next\": state_next,\n",
    "        \"observation\": observation,\n",
    "        \"observation_next\": observation_next,\n",
    "        \"reward\": reward, \"action\": action, \"terminal\": 1. - done,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7a96b99d-86c1-4f67-8533-50347143a00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_    = jit(score)\n",
    "forecast_ = partial(forecast, \n",
    "                    step_fn=world, \n",
    "                    horizon=250,\n",
    "                    action_dim=3, \n",
    "                    minval=None, \n",
    "                    maxval=None,     # Number of discrete actions possible\n",
    "                    action_type='discrete')\n",
    "\n",
    "#forecast_(rng, (state_0, observation_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d8c9ebda-93c6-444c-bd73-123c52472836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(0, dtype=int32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng, rng_reset = jax.random.split(rng, 2)\n",
    "state_0, observation_0  = env.reset(rng_reset)\n",
    "action, _ = plan(rng, (state_0, observation_0), jit(forecast_), jit(score))\n",
    "action[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f52902a4-7694-43b5-8bc9-abc5476bc26e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5222c85209e4621847a46046c2e3fa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-200.0\n",
      "CPU times: user 8.94 s, sys: 418 ms, total: 9.36 s\n",
      "Wall time: 8.46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# RS:Model.\n",
    "score = 0\n",
    "rng, rng_reset = jax.random.split(rng, 2)\n",
    "state, observation = env.reset(rng_reset)\n",
    "list_states = []\n",
    "for _ in tqdm.notebook.trange(200):\n",
    "    rng, rng_plan = jax.random.split(rng, 2)\n",
    "    list_states.append(state)\n",
    "    action = plan(rng_plan, (state, observation), forecast_, score_,  population=5000)[0][0]\n",
    "    state, observation, reward, terminal, info = env.step(state, action)\n",
    "    score += reward\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a8b436e5-d6dc-4a7c-b8b2-cd2181f18afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, info = render(list_states[0], {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3a85bc17-a7ab-45e9-a81c-773bab4ad468",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in list_states:\n",
    "    render(s, info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c3ece5-6d0b-4475-b67e-6a408f7bc8a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
